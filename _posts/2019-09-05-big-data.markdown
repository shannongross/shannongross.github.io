---
layout: post
title: "The politicization of big data"
date: 2019-09-05
description: Big data and politics. # Add post description (optional)
img: divide.jpg  # Add image post (optional)
tags: [big data, policy analysis]
---
We live in an age of data. **Datafication** refers to the increasing number of activities conducted in a semi-digital environment, where sensors, devices, and apps collect data about these activities. As a result, there are more and different datasets one can use to (partially) answer the same question. For instance, the question *what is the current unemployment rate?* seems simple enough at face value to provide a scientific answer. Yet, there are many different definitions, techniques, and datasets used to calculate the unemployment rate, making this seemingly simple metric highly contested.

A common definition of "big data" is based on multiple "V's" that each denote a characteristic of big data: volume, variety, velocity, etc. However, this definition presents a operational problem because we can’t have a meaningful threshold for any of these (i.e. what is a "big" volume?). Instead, it may be more useful to think of **Big Data** analysis as the:
> combination of multiple, large datasets from various sources (unstructured and structured, internal and external) and the application of advanced analytic techniques to gain new insights beyond the applications that the data were originally collected for.

Policymaking and strategy development occurred long before the advent of big data. There is a great deal of research to support the idea that policy decisions are often not based on evidence, but instead made by "gut feeling" or by following precedent. So why do we need data for policy? We don’t really. But big data can be tremendously useful for solving policy problems. A major problem, however, is that people are often unaware of the assumptions behind the data they use.

Data is assumed to be objective because we have institutionalized its use, however, we must understand that no analysis is truly ‘objective’ and all data collection and modelling captures just part of the picture. Failing to fully understand the context of information can lead to **big data discrimination**, where models are trained on historical data which codifies patterns of discrimination.

## The role of big data analysts in policymaking
Analysts provide computational skills that can support politicians in gaining insight from big data. However, big data analysis frequently involves more "political" decisions to be made during the analysis compared to "normal" data. The way that assumptions are quantified and relationships are structured may already inject political subjectivity into the analysis.

As an analyst working on policy-relevant concerns, it is important to consider the shortcomings behind big data. Analysts must take care not to take data only at their face value, but to interrogate the assumptions and methods used to create them. Especially for contentious political issues- if you as the analyst do not question these characteristics then your political opponent is sure to!

## Convincing policymakers of big data evidence
In the world of big data, it is getting easier to make the claim that there are different sets of facts (alternative facts). It is easier to criticize data, bring up competing data, and argue system boundaries. In order to provide policy support in this increasingly complex and data-driven world, the following are recommended:
- Construct the facts along with the stakeholders to make agreement more likely.
- Make work more attractive to policymakers by showing strategies that can help solve stalemates.
- Redefine and broaden problems. Create new options for decision makers.
- Present a variety of solutions or solutions that have wiggle room.
- Evolve from a solely "objective/scientific" external expert toward a policy facilitator role.
